{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MAMI Task B Github",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "so_vMMr7kqTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amJ-AHG-7JAF"
      },
      "outputs": [],
      "source": [
        "# 4.15.0\n",
        "!pip install transformers==4.15.0\n",
        "!pip install ekphrasis\n",
        "!pip install emoji"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "EJyQiKhNVWQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from transformers import ViTFeatureExtractor, TFViTModel, TFViTForImageClassification, BertTokenizerFast, TFBertModel\n",
        "from PIL import Image\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.data import Dataset\n",
        "from tensorflow import keras\n",
        "from collections import Counter\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "transformers.__version__"
      ],
      "metadata": {
        "id": "xS-AUdar7sIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir('images')\n",
        "import zipfile\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/mami/training.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/images')"
      ],
      "metadata": {
        "id": "p2Qvvaej_hED"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir('images_test')\n",
        "import zipfile\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/mami/test.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/images_test')"
      ],
      "metadata": {
        "id": "5p71fHf-7gUK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/training.csv', sep='delimiter', header=None, skiprows=1)"
      ],
      "metadata": {
        "id": "fAohk4hg8A_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "l4CX_hEY-Weh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = df[0].apply(lambda string: np.array(string.split('\\t'), dtype='str'))\n",
        "train_data = np.asarray(train_data)\n",
        "train_array_ = np.stack(train_data)\n",
        "print(np.shape(train_array_))"
      ],
      "metadata": {
        "id": "_lCFNsD1-Z4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.DataFrame(train_array_)\n",
        "df2.head()"
      ],
      "metadata": {
        "id": "m3IpoY7zDlar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_array = df2.loc[df2[1] == '1']\n",
        "train_array = train_array.reset_index()"
      ],
      "metadata": {
        "id": "0DggqV4UEGh5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_array.info()"
      ],
      "metadata": {
        "id": "taEPQxwo9L6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filenames = np.array(train_array[0])\n",
        "text = np.array(train_array[6])\n",
        "Y_shaming = train_array[2]\n",
        "Y_stereotype = train_array[3]\n",
        "Y_objectification = train_array[4]\n",
        "Y_violence = train_array[5]\n",
        "\n",
        "Y_shaming = np.array(Y_shaming).astype(np.float32)\n",
        "Y_stereotype = np.array(Y_stereotype).astype(np.float32)\n",
        "Y_objectification = np.array(Y_objectification).astype(np.float32)\n",
        "Y_violence = np.array(Y_violence).astype(np.float32)\n",
        "\n",
        "print(Counter(Y_shaming))\n",
        "print(Counter(Y_stereotype))\n",
        "print(Counter(Y_objectification))\n",
        "print(Counter(Y_violence))"
      ],
      "metadata": {
        "id": "xlC0BbxzZBDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h6>Text Train Split</h6>"
      ],
      "metadata": {
        "id": "XZVWyVGya3Mt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "J7UMBcpeZx2T"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filenames_train, filenames_val, text_train, text_val, Y_shaming_train, Y_shaming_val, Y_stereotype_train, Y_stereotype_val, Y_objectification_train, Y_objectification_val, Y_violence_train, Y_violence_val = train_test_split(filenames, text, Y_shaming, Y_stereotype, Y_objectification, Y_violence, test_size=0.05, random_state=3)"
      ],
      "metadata": {
        "id": "V2lGHNy5ZVQI"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train = np.column_stack((Y_shaming_train, Y_stereotype_train, Y_objectification_train, Y_violence_train))\n",
        "print(np.shape(Y_train))"
      ],
      "metadata": {
        "id": "Xlw_3-J1RVwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train\")\n",
        "print(np.shape(filenames_train), type(filenames_train))\n",
        "print(np.shape(text_train), type(text_train))\n",
        "print(np.shape(Y_shaming_train), type(Y_shaming_train))\n",
        "print(np.shape(Y_stereotype_train), type(Y_stereotype_train))\n",
        "print(np.shape(Y_objectification_train), type(Y_objectification_train))\n",
        "print(np.shape(Y_violence_train), type(Y_violence_train))\n",
        "print(\"Val\")\n",
        "print(np.shape(filenames_val))\n",
        "print(np.shape(text_val))\n",
        "print(np.shape(Y_shaming_val))\n",
        "print(np.shape(Y_stereotype_val))\n",
        "print(np.shape(Y_objectification_val))\n",
        "print(np.shape(Y_violence_val))"
      ],
      "metadata": {
        "id": "GP3jB7OIZVMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h6>Text pre-processing</h6>"
      ],
      "metadata": {
        "id": "ixx5hs5Za2JT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
        "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
        "from ekphrasis.dicts.emoticons import emoticons"
      ],
      "metadata": {
        "id": "s0VuTFUiZVJS"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_processor = TextPreProcessor(\n",
        "    # terms that will be normalized\n",
        "    normalize=['url', 'email', 'percent', 'money', 'phone', 'user',\n",
        "        'time', 'url', 'date', 'number'],\n",
        "    # terms that will be annotated\n",
        "    annotate={\"hashtag\", \"allcaps\", \"elongated\", \"repeated\",\n",
        "        'emphasis', 'censored'},\n",
        "    fix_html=True,  # fix HTML tokens\n",
        "    \n",
        "    # corpus from which the word statistics are going to be used \n",
        "    # for word segmentation \n",
        "    segmenter=\"twitter\", \n",
        "    \n",
        "    # corpus from which the word statistics are going to be used \n",
        "    # for spell correction\n",
        "    corrector=\"twitter\", \n",
        "    \n",
        "    unpack_hashtags=True,  # perform word segmentation on hashtags\n",
        "    unpack_contractions=True,  # Unpack contractions (can't -> can not)\n",
        "    spell_correct_elong=True,  # spell correction for elongated words\n",
        "    \n",
        "    # select a tokenizer. You can use SocialTokenizer, or pass your own\n",
        "    # the tokenizer, should take as input a string and return a list of tokens\n",
        "    tokenizer=SocialTokenizer(lowercase=True).tokenize,\n",
        "    \n",
        "    # list of dictionaries, for replacing tokens extracted from the text,\n",
        "    # with other expressions. You can pass more than one dictionaries.\n",
        "    dicts=[emoticons]\n",
        ")"
      ],
      "metadata": {
        "id": "EuT4bqHJbB8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_text(texts,i,j):\n",
        "    for u in range(i,j):\n",
        "        print(texts[u])\n",
        "        print()"
      ],
      "metadata": {
        "id": "Hvr1XOf-bB5E"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_text(text_train,0,5)\n",
        "print(\"##############################################################################################################\")\n",
        "print_text(text_val,0,5)"
      ],
      "metadata": {
        "id": "2SHN3YeybB2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions for chat word conversion\n",
        "f = open(\"slang.txt\", \"r\")\n",
        "chat_words_str = f.read()\n",
        "chat_words_map_dict = {}\n",
        "chat_words_list = []\n",
        "\n",
        "for line in chat_words_str.split(\"\\n\"):\n",
        "    if line != \"\":\n",
        "        cw = line.split(\"=\")[0]\n",
        "        cw_expanded = line.split(\"=\")[1]\n",
        "        chat_words_list.append(cw)\n",
        "        chat_words_map_dict[cw] = cw_expanded\n",
        "chat_words_list = set(chat_words_list)\n",
        "\n",
        "def chat_words_conversion(text):\n",
        "    new_text = []\n",
        "    for w in text.split():\n",
        "        if w.upper() in chat_words_list:\n",
        "            new_text.append(chat_words_map_dict[w.upper()])\n",
        "        else:\n",
        "            new_text.append(w)\n",
        "    return \" \".join(new_text)"
      ],
      "metadata": {
        "id": "gQ4cYQKubBzZ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_train = pd.Series(text_train)\n",
        "text_val = pd.Series(text_val)"
      ],
      "metadata": {
        "id": "p-RGux_eb4rC"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chat word conversion\n",
        "# Training set\n",
        "text_train = text_train.apply(lambda text: chat_words_conversion(text))\n",
        "print_text(text_train,0,5)\n",
        "\n",
        "print(\"********************************************************************************\")\n",
        "\n",
        "# Validation set\n",
        "text_val = text_val.apply(lambda text: chat_words_conversion(text))\n",
        "print_text(text_val,0,5)"
      ],
      "metadata": {
        "id": "B45gKA2ZbBw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ekphrasis_pipe(sentence):\n",
        "    cleaned_sentence = \" \".join(text_processor.pre_process_doc(sentence))\n",
        "    return cleaned_sentence"
      ],
      "metadata": {
        "id": "jnyAeJgLbBtp"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training set\n",
        "text_train = text_train.apply(lambda text: ekphrasis_pipe(text))\n",
        "print(\"Training set completed.......\")\n",
        "#Validation set\n",
        "text_val = text_val.apply(lambda text: ekphrasis_pipe(text))\n",
        "print(\"Validation set completed.......\")"
      ],
      "metadata": {
        "id": "O3VSPXylbBrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "u = lambda text: len(text.split(\" \"))\n",
        "sentence_lengths = []\n",
        "for x in text_train:\n",
        "    sentence_lengths.append(u(x))\n",
        "print(sorted(sentence_lengths)[-500:])\n",
        "print(len(sentence_lengths))"
      ],
      "metadata": {
        "id": "ObiKEw2ucqSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "</h6>Text processing complete</h6>"
      ],
      "metadata": {
        "id": "VCqoO60Rcr1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaTokenizerFast, TFRobertaModel, MPNetTokenizerFast, TFMPNetModel, ElectraTokenizerFast, TFElectraModel, XLNetTokenizerFast, TFXLNetModel, AlbertTokenizerFast, TFAlbertModel"
      ],
      "metadata": {
        "id": "qTlMhqMkoNaD"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "bFp70daooPCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings = tokenizer(list(text_train), max_length=80, truncation=True, padding=\"max_length\", return_tensors='tf')\n",
        "print(np.shape(train_encodings[\"input_ids\"]))\n",
        "\n",
        "val_encodings = tokenizer(list(text_val), max_length=80, truncation=True, padding=\"max_length\", return_tensors='tf')\n",
        "print(np.shape(val_encodings[\"input_ids\"]))"
      ],
      "metadata": {
        "id": "4Pxcc2BxAs2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_processing(filename):\n",
        "  # Read Image\n",
        "  image_string = tf.io.read_file('/content/images/TRAINING/' + filename)\n",
        "  img = tf.io.decode_jpeg(image_string, channels=3)\n",
        "  # Resize image\n",
        "  img = tf.image.resize(img, [224,224], method='bilinear')\n",
        "  # Normalise image\n",
        "  img = tf.cast(img, tf.float32)\n",
        "  img = tf.math.divide(img, 255.0)\n",
        "  img = tf.math.subtract(img, 0.5)\n",
        "  img = tf.math.divide(img, 0.5)\n",
        "  # Move channel axis\n",
        "  img = tf.experimental.numpy.moveaxis(img, -1, 0)\n",
        "\n",
        "  return img"
      ],
      "metadata": {
        "id": "7bSxXlZc-xlE"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16 # for tpu 128\n",
        "def configure_for_performance(ds):\n",
        "  # ds = ds.cache()\n",
        "  ds = ds.shuffle(buffer_size=1000)\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "  return ds"
      ],
      "metadata": {
        "id": "Vj0CxeY7JEIN"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset(filenames, encodings, Y_shame, Y_stereotype, Y_objectification, Y_violence):\n",
        "  image_names = Dataset.from_tensor_slices(filenames) # ==> 3x2 tensor\n",
        "  image_features = image_names.map(image_processing)\n",
        "\n",
        "  text_features = Dataset.from_tensor_slices(encodings[\"input_ids\"])\n",
        "  text_masks = Dataset.from_tensor_slices(encodings[\"attention_mask\"])\n",
        "\n",
        "  labels_shame = Dataset.from_tensor_slices(Y_shame)\n",
        "  labels_stereotype = Dataset.from_tensor_slices(Y_stereotype)\n",
        "  labels_objectification = Dataset.from_tensor_slices(Y_objectification)\n",
        "  labels_violence = Dataset.from_tensor_slices(Y_violence)\n",
        "  final_labels = Dataset.zip((labels_shame, labels_stereotype, labels_objectification, labels_violence))\n",
        "\n",
        "  features = Dataset.zip((image_features, text_features, text_masks))\n",
        "\n",
        "  dataset = Dataset.zip((features, final_labels))\n",
        "\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "nxLce-8Fdl-z"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = get_dataset(filenames_train, train_encodings, Y_shaming_train, Y_stereotype_train, Y_objectification_train, Y_violence_train)\n",
        "dataset_train = configure_for_performance(dataset_train)"
      ],
      "metadata": {
        "id": "oK2vMAdPezHt"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_features_val = np.zeros((250,3,224,224))\n",
        "for i in range(0, 250):\n",
        "  images_features_val[i] = image_processing(filenames_val[i])"
      ],
      "metadata": {
        "id": "vXeqVId4xXJH"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Attention Model base models\n",
        "# For concatenation models simply replace tf.keras.layers.Attention() with tf.keras.layers.Concatenate()\n",
        "def test(input_shape):\n",
        "    img_input = keras.Input(shape=(3, 224, 224), dtype='float32')\n",
        "    txt_input = keras.Input(shape=input_shape, dtype='int32')\n",
        "    input_masks = keras.Input(shape=input_shape, dtype='int32')\n",
        "\n",
        "    # Text\n",
        "    model_txt = TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
        "    layer_txt = model_txt.layers[0]\n",
        "    text_seq = layer_txt([txt_input, input_masks])[0]\n",
        "\n",
        "    # Images\n",
        "    model_images = TFViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "    layer_img = model_images.layers[0]\n",
        "    img_seq = layer_img(img_input)[0]\n",
        "    \n",
        "    joint_features_shame = tf.keras.layers.Attention()([img_seq, text_seq])\n",
        "    joint_features_shame = tf.keras.layers.Conv1D(32, 30, 15)(joint_features_shame)\n",
        "    joint_features_shame = tf.keras.layers.Flatten()(joint_features_shame)\n",
        "    joint_features_shame = keras.layers.Dense(32, activation='relu')(joint_features_shame)\n",
        "    shame_ = keras.layers.BatchNormalization()(joint_features_shame)\n",
        "\n",
        "    joint_features_stereotype = tf.keras.layers.Attention()([img_seq, text_seq])\n",
        "    joint_features_stereotype = tf.keras.layers.Conv1D(32, 30, 15)(joint_features_stereotype)\n",
        "    joint_features_stereotype = tf.keras.layers.Flatten()(joint_features_stereotype)\n",
        "    joint_features_stereotype = keras.layers.Dense(32, activation='relu')(joint_features_stereotype)\n",
        "    stereotype_ = keras.layers.BatchNormalization()(joint_features_stereotype)\n",
        "\n",
        "    joint_features_objectificaton = tf.keras.layers.Attention()([img_seq, text_seq])\n",
        "    joint_features_objectificaton = tf.keras.layers.Conv1D(32, 30, 15)(joint_features_objectificaton)\n",
        "    joint_features_objectificaton = tf.keras.layers.Flatten()(joint_features_objectificaton)\n",
        "    joint_features_objectificaton = keras.layers.Dense(32, activation='relu')(joint_features_objectificaton)\n",
        "    objectification_ = keras.layers.BatchNormalization()(joint_features_objectificaton)\n",
        "\n",
        "    joint_features_violence = tf.keras.layers.Attention()([img_seq, text_seq])\n",
        "    joint_features_violence = tf.keras.layers.Conv1D(32, 30, 15)(joint_features_violence)\n",
        "    joint_features_violence = tf.keras.layers.Flatten()(joint_features_violence)\n",
        "    joint_features_violence = keras.layers.Dense(32, activation='relu')(joint_features_violence)\n",
        "    violence_ = keras.layers.BatchNormalization()(joint_features_violence)\n",
        "\n",
        "    shame_ = keras.layers.Dense(1, activation='sigmoid')(shame_)\n",
        "    stereotype_ = keras.layers.Dense(1, activation='sigmoid')(stereotype_)\n",
        "    objectification_ = keras.layers.Dense(1, activation='sigmoid')(objectification_)\n",
        "    violence_ = keras.layers.Dense(1, activation='sigmoid')(violence_)\n",
        "    \n",
        "    model = keras.Model(inputs=[img_input, txt_input, input_masks], outputs=[shame_, stereotype_, objectification_, violence_])    \n",
        "    return model"
      ],
      "metadata": {
        "id": "YEwBmg_zll2_"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EvaluationMetric(keras.callbacks.Callback):   \n",
        "    \n",
        "    def __init__(self, val_img_features, val_encodings, val_masks, Y_val):\n",
        "        super(EvaluationMetric, self).__init__()\n",
        "        self.val_encodings = val_encodings\n",
        "        self.val_masks = val_masks\n",
        "        self.Y_val = Y_val\n",
        "        self.val_img_features = val_img_features\n",
        "    \n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        print(\"\\nTraining...\")\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        print(\"\\nEvaluating...\")\n",
        "        val_prediction = self.model.predict([self.val_img_features, self.val_encodings, self.val_masks])\n",
        "        \n",
        "        pred = np.round(val_prediction)\n",
        "\n",
        "        from sklearn.metrics import classification_report\n",
        "        print(\"Shame\")\n",
        "        print(classification_report(self.Y_val[:,0], pred[0][:,0], digits=3))\n",
        "        print(\"##################################################################\")\n",
        "        \n",
        "        print(\"Stereotype\")\n",
        "        print(classification_report(self.Y_val[:,1], pred[1][:,0], digits=3))\n",
        "        print(\"##################################################################\")\n",
        "\n",
        "        print(\"Objectification\")\n",
        "        print(classification_report(self.Y_val[:,2], pred[2][:,0], digits=3))\n",
        "        print(\"##################################################################\")\n",
        "\n",
        "        print(\"Violence\")\n",
        "        print(classification_report(self.Y_val[:,3], pred[3][:,0], digits=3))\n",
        "        print(\"##################################################################\")\n",
        "\n",
        "evaluation_metric = EvaluationMetric(images_features_val, val_encodings[\"input_ids\"], val_encodings[\"attention_mask\"], np.column_stack((Y_shaming_val, Y_stereotype_val, Y_objectification_val, Y_violence_val)))"
      ],
      "metadata": {
        "id": "Ieg_DTqrX8KH"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint(filepath='/content/vit-bert.{epoch:03d}.h5',\n",
        "                                 verbose = 0,\n",
        "                                 save_weights_only=True,\n",
        "                                 epoch=1)"
      ],
      "metadata": {
        "id": "uRslZCZUkCCn"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Counter(Y_shaming_train))\n",
        "print(Counter(Y_stereotype_train))\n",
        "print(Counter(Y_objectification_train))\n",
        "print(Counter(Y_violence_train))"
      ],
      "metadata": {
        "id": "bWuu4xJS5TJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.Adam(learning_rate=4e-5)\n",
        "loss_fun = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "metric = [tf.metrics.BinaryAccuracy(), tf.metrics.Precision(), tf.metrics.Recall()]\n",
        "model = test((80,))\n",
        "model.compile(optimizer=optimizer, loss=loss_fun, metrics=metric)"
      ],
      "metadata": {
        "id": "8IEuSqSqK_oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "PA1Cu7CJNm41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(\n",
        "    model)"
      ],
      "metadata": {
        "id": "G11KmoRuOARu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# history = model.fit(\n",
        "#     dataset_train,\n",
        "#     callbacks = [evaluation_metric, checkpoint],\n",
        "#     epochs=10\n",
        "# )"
      ],
      "metadata": {
        "id": "hQe7RKxIPv1F"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import gc\n",
        "# del images_features_val\n",
        "# gc.collect()"
      ],
      "metadata": {
        "id": "HVYb4mJFlqkO"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h6>Test Set</h6>"
      ],
      "metadata": {
        "id": "sg8thWcvkZvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv('/content/test.csv', sep='delimiter', header=None, skiprows=1)"
      ],
      "metadata": {
        "id": "2DnGqzAtky5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "654a1617-204c-4c30-b987-03d8698a1e7d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  return func(*args, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.info()"
      ],
      "metadata": {
        "id": "-hnVprr_kzxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = df_test[0].apply(lambda string: np.array(string.split('\\t'), dtype='str'))\n",
        "test_data = np.asarray(test_data)\n",
        "test_array = np.stack(test_data)\n",
        "print(np.shape(test_array))"
      ],
      "metadata": {
        "id": "EwV-MhD0lAzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filenames_test = test_array[:,0]\n",
        "text_test = test_array[:,1]"
      ],
      "metadata": {
        "id": "rsfQtKrWZYdd"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_test = pd.Series(text_test)\n",
        "text_test = text_test.apply(lambda text: chat_words_conversion(text))\n",
        "text_test = text_test.apply(lambda text: ekphrasis_pipe(text))"
      ],
      "metadata": {
        "id": "PRUxIgUTZZ_x"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_processing_test(filename):\n",
        "  # Read Image\n",
        "  image_string = tf.io.read_file('/content/images_test/test/' + filename)\n",
        "  img = tf.io.decode_jpeg(image_string, channels=3)\n",
        "  # Resize image\n",
        "  img = tf.image.resize(img, [224,224], method='bilinear')\n",
        "  # Normalise image\n",
        "  img = tf.cast(img, tf.float32)\n",
        "  img = tf.math.divide(img, 255.0)\n",
        "  img = tf.math.subtract(img, 0.5)\n",
        "  img = tf.math.divide(img, 0.5)\n",
        "  # Move channel axis\n",
        "  img = tf.experimental.numpy.moveaxis(img, -1, 0)\n",
        "\n",
        "  return img"
      ],
      "metadata": {
        "id": "B9J69fJKmDqN"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_features_test = np.zeros((1000,3,224,224))\n",
        "for i in range(0, 1000):\n",
        "  images_features_test[i] = image_processing_test(filenames_test[i])"
      ],
      "metadata": {
        "id": "Dm-9YN_EZeWk"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_encodings = tokenizer(list(text_test), max_length=80, truncation=True, padding=\"max_length\", return_tensors='tf')\n",
        "print(np.shape(test_encodings[\"input_ids\"]))"
      ],
      "metadata": {
        "id": "wxYfJ9EBZbpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer_test = model.predict([images_features_test, test_encodings[\"input_ids\"], test_encodings[\"attention_mask\"]])"
      ],
      "metadata": {
        "id": "motKWOSIZd45"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_answer_list(answer):\n",
        "  print(np.shape(answer))\n",
        "  final = (np.round(answer)).astype(np.int)\n",
        "  print(\"Shame\")\n",
        "  print(Counter(final[0][:,0]))\n",
        "  print(\"Stereotype\")\n",
        "  print(Counter(final[1][:,0]))\n",
        "  print(\"Objectify\")\n",
        "  print(Counter(final[2][:,0]))\n",
        "  print(\"Violence\")\n",
        "  print(Counter(final[3][:,0]))\n",
        "  return final"
      ],
      "metadata": {
        "id": "GDnAGxDAZhrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_answer = get_answer_list(answer_test)"
      ],
      "metadata": {
        "id": "jSJjE6e5bZFD"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Counter(Y_shaming))\n",
        "print(Counter(Y_stereotype))\n",
        "print(Counter(Y_objectification))\n",
        "print(Counter(Y_violence))"
      ],
      "metadata": {
        "id": "a5IY5veyZXfJ"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer_list = final_answer\n",
        "answer_names = list(filenames_test)"
      ],
      "metadata": {
        "id": "x1gXn70bZmXc"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('answer.txt', 'w') as outf:\n",
        "  for i in range(0, 999):\n",
        "    outf.write(answer_names[i] + '\\t' + '0' + '\\t' + str(answer_list[0][i,0]) + '\\t' + str(answer_list[1][i,0]) + '\\t' + str(answer_list[2][i,0]) + '\\t' + str(answer_list[3][i,0]) + '\\n')\n",
        "  outf.write((answer_names[999] + '\\t' + '0' + '\\t' + str(answer_list[0][999,0]) + '\\t' + str(answer_list[1][999,0]) + '\\t' + str(answer_list[2][999,0]) + '\\t' + str(answer_list[3][999,0])))"
      ],
      "metadata": {
        "id": "5quao_41Znv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zipfile.ZipFile('answer.zip', mode='w').write(\"answer.txt\")"
      ],
      "metadata": {
        "id": "q6gqpi3CZpRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MmuRGX42mvGx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}